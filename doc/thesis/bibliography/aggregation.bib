% Encoding: UTF-8
@inproceedings{Ianina2017,
  title={Multi-objective topic modeling for exploratory search in tech news},
  author={Ianina, Anastasia and Golitsyn, Lev and Vorontsov, Konstantin},
  booktitle={Conference on Artificial Intelligence and Natural Language},
  pages={181--193},
  year={2017},
  organization={Springer}
}


@inproceedings{Zhai2012,
abstract = {Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for exploring document collections. Because of the increasing prevalence of large datasets, there is a need to improve the scalability of inference for LDA. In this paper, we introduce a novel and flexible large scale topic modeling package in MapReduce (Mr. LDA). As opposed to other techniques which use Gibbs sampling, our proposed framework uses variational inference, which easily fits into a distributed environment. More importantly, this variational implementation, unlike highly tuned and specialized implementations based on Gibbs sampling, is easily extensible. We demonstrate two extensions of the models possible with this scalable framework: informed priors to guide topic discovery and extracting topics from a multilingual corpus. We compare the scalability of Mr. LDA against Mahout, an existing large scale topic modeling package. Mr. LDA out-performs Mahout both in execution speed and held-out likelihood.},
address = {New York, New York, USA},
author = {Zhai, Ke and Boyd-Graber, Jordan and Asadi, Nima and Alkhouja, Mohamad L.},
booktitle = {Proceedings of the 21st international conference on World Wide Web - WWW '12},
doi = {10.1145/2187836.2187955},
isbn = {9781450312295},
issn = {1450312292},
pages = {879},
publisher = {ACM Press},
title = {{Mr. LDA}},
url = {http://dl.acm.org/citation.cfm?doid=2187836.2187955},
year = {2012}
}


@article{Pujara2012,
abstract = {In the past decade, a number of advances in topic modeling have produced sophis-ticated models that are capable of generating hierarchies of topics. One challenge for these models is scalability: they are incapable of working at the massive scale of millions of documents and hundreds of thousands of terms. We address this challenge with a technique that learns a hierarchy of topics by iteratively apply-ing topic models and processing subtrees of the hierarchy in parallel. This ap-proach has a number of scalability advantages compared to existing techniques, and shows promising results in experiments assessing runtime and human evalu-ations of quality. We detail extensions to this approach that may further improve hierarchical topic modeling for large-scale applications.},
author = {Pujara, Jay and Skomoroch, Peter},
journal = {NIPS Workshop on Big Learning},
title = {{Large-Scale Hierarchical Topic Models}},
year = {2012}
}


@article{hHDP,
abstract = {This paper presents hHDP, a hierarchical algorithm for representing a document collection as a hi-erarchy of latent topics, based on Dirichlet process priors. The hierarchical nature of the algorithm refers to the Bayesian hierarchy that it comprises, as well as to the hierarchy of the latent topics. hHDP relies on nonparametric Bayesian priors and it is able to infer a hierarchy of topics, without making any assumption about the depth of the learned hierarchy and the branching factor at each level. We evaluate the proposed method on real-world data sets in document modeling, as well as in ontology learning, and provide qualitative and quantitative evaluation results, showing that the model is robust, it models accurately the training data set and is able to generalize on held-out data.},
author = {Zavitsanos, Elias and Gr, Paliourg@iit Demokritos and Vouros, George A and Gr, Georgev@aegean},
isbn = {1532-4435},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {hierarchical Dirichlet processes,ontol-ogy learning from text,probabilistic topic models,topic distributions,topic hierarchy},
mendeley-groups = {ARTM},
title = {{Non-Parametric Estimation of Topic Hierarchies from Texts with Hierarchical Dirichlet Processes Georgios Paliouras}},
year = {2011}
}


@InProceedings{IncClust2,
  title =	"Incremental Construction of Topic Hierarchies using
		 Hierarchical Term Clustering",
  author =	"Ricardo M. Marcacini and Solange O. Rezende",
  publisher =	"Knowledge Systems Institute Graduate School",
  year = 	"2010",
  bibdate =	"2010-11-29",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/seke/seke2010.html#MarcaciniR10",
  booktitle =	"SEKE",
  crossref =	"conf/seke/2010",
  ISBN = 	"1-891706-26-8",
  pages =	"553",
}

@InProceedings{extLDA2,
  author    = {Chaitanya Chemudugunta and Padhraic Smyth and Mark Steyvers},
  title     = {Modeling General and Specific Aspects of Documents with a Probabilistic Topic Model},
  booktitle = {NIPS},
  year      = {2006},
  editor    = {Bernhard Sch{\"o}lkopf and John C. Platt and Thomas Hofmann},
  pages     = {241--248},
  publisher = {MIT Press},
  bibdate   = {2014-12-10},
  isbn      = {0-262-19568-2},
  url       = {http://papers.nips.cc/book/advances-in-neural-information-processing-systems-19-2006},
}

@Article{hARTM,
  author = {Chirkova, NA and Vorontsov, KV},
  title  = {Additive Regularization for Hierarchical Multimodal Topic Modeling},
  year   = {2016},
}

@InCollection{Frei2017,
  author        = {Frei, Oleksandr and Apishev, Murat},
  title         = {Parallel Non-blocking Deterministic Algorithm for Online Topic Modeling},
  booktitle     = {Analysis of Images, Social Networks and Texts},
  publisher     = {Springer},
  year          = {2017},
  month         = jan,
  isbn          = {978-3-319-52919-6},
  __markedentry = {[el1318:]},
  abstract      = {In this paper we present a new asynchronous algorithm for learning additively regularized topic models and discuss the main architectural details of our implementation. The key property of the new algorithm is that it behaves in a fully deterministic fashion, which is typically hard to achieve in a non-blocking parallel implementation. The algorithm had been recently implemented in the BigARTM library (http://bigartm.org). Our new algorithm is compatible with all features previously introduced in BigARTM library, including multimodality, regularizers and scores calculation. While the existing BigARTM implementation compares favorably with alternative packages such as Vowpal Wabbit or Gensim, the new algorithm brings further improvements in CPU utilization, memory usage, and spends even less time to achieve the same perplexity.},
  date          = {2017-01-01},
  doi           = {10.1007/978-3-319-52920-2_13},
  url           = {http://dx.doi.org/10.1007/978-3-319-52920-2_13},
}

@Article{ARTM4,
  author        = {Vorontsov, Konstantin and Potapenko, Anna},
  title         = {Additive regularization of topic models},
  journal       = {Machine Learning},
  year          = {2015},
  volume        = {101},
  number        = {1-3},
  pages         = {303},
  month         = oct,
  __markedentry = {[el1318:]},
  abstract      = {Probabilistic topic modeling of text collections has been recently developed mainly within the framework of graphical models and Bayesian inference. In this paper we introduce an alternative semi-probabilistic approach, which we call additive regularization of topic models (ARTM). Instead of building a purely probabilistic generative model of text we regularize an ill-posed problem of stochastic matrix factorization by maximizing a weighted sum of the log-likelihood and additional criteria. This approach enables us to combine probabilistic assumptions with linguistic and problem-specific requirements in a single multi-objective topic model. In the theoretical part of the work we derive the regularized EM-algorithm and provide a pool of regularizers, which can be applied together in any combination. We show that many models previously developed within Bayesian framework can be inferred easier within ARTM and in some cases generalized. In the experimental part we show that a combination of sparsing, smoothing, and decorrelation improves several quality measures at once with almost no loss of the likelihood.},
  date          = {2015-10-01},
  doi           = {10.1007/s10994-014-5476-6},
  publisher     = {Springer},
  url           = {http://dx.doi.org/10.1007/s10994-014-5476-6},
}

@InCollection{Vorontsov2015a,
  author        = {Vorontsov, Konstantin and Frei, Oleksandr and Apishev, Murat and Romov, Peter and Dudarenko, Marina},
  title         = {BigARTM: Open Source Library for Regularized Multimodal Topic Modeling of Large Collections},
  booktitle     = {Analysis of Images, Social Networks and Texts},
  publisher     = {Springer},
  year          = {2015},
  month         = jan,
  isbn          = {978-3-319-26122-5},
  __markedentry = {[el1318:]},
  abstract      = {Probabilistic topic modeling of text collections is a powerful tool for statistical text analysis. In this paper we announce the BigARTM open source project (http://bigartm.org) for regularized multimodal topic modeling of large collections. Several experiments on Wikipedia corpus show that BigARTM performs faster and gives better perplexity comparing to other popular packages, such as Vowpal Wabbit and Gensim. We also demonstrate several unique BigARTM features, such as additive combination of regularizers, topic sparsing and decorrelation, multimodal and multilanguage modeling, which are not available in the other software packages for topic modeling.},
  date          = {2015-01-01},
  doi           = {10.1007/978-3-319-26123-2_36},
  url           = {http://dx.doi.org/10.1007/978-3-319-26123-2_36},
}

@Article{ARTM2,
  author        = {Vorontsov, Konstantin and Potapenko, Anna and Plavin, Alexander},
  title         = {Additive Regularization of Topic Models for Topic Selection and Sparse Factorization},
  journal       = {Statistical Learning and Data Sciences},
  year          = {2015},
  month         = jan,
  __markedentry = {[el1318:]},
  abstract      = {Probabilistic topic modeling of text collections is a powerful tool for statistical text analysis. Determining the optimal number of topics remains a challenging problem in topic modeling. We propose a simple entropy regularization for topic selection in terms of Additive Regularization of Topic Models (ARTM), a multicriteria approach for combining regularizers. The entropy regularization gradually eliminates insignificant and linearly dependent topics. This process converges to the correct value on semi-real data. On real text collections it can be combined with sparsing, smoothing and decorrelation regularizers to produce a sequence of models with different numbers of well interpretable topics.},
  date          = {2015-01-01},
  doi           = {10.1007/978-3-319-17091-6_14},
  publisher     = {Springer},
  url           = {http://dx.doi.org/10.1007/978-3-319-17091-6_14},
}

@Article{ARTM3,
  author        = {Vorontsov, K. V.},
  title         = {Additive regularization for topic models of text collections},
  journal       = {Doklady Mathematics},
  year          = {2014},
  volume        = {89},
  number        = {3},
  pages         = {301},
  month         = may,
  __markedentry = {[el1318:]},
  date          = {2014-05-01},
  doi           = {10.1134/S1064562414020185},
  publisher     = {Springer},
  url           = {http://dx.doi.org/10.1134/S1064562414020185},
}

@InCollection{Vorontsov2014,
  author        = {Vorontsov, Konstantin and Potapenko, Anna},
  title         = {Tutorial on Probabilistic Topic Modeling: Additive Regularization for Stochastic Matrix Factorization},
  booktitle     = {Analysis of Images, Social Networks and Texts},
  publisher     = {Springer},
  year          = {2014},
  month         = jan,
  isbn          = {978-3-319-12579-4},
  __markedentry = {[el1318:]},
  abstract      = {Probabilistic topic modeling of text collections is a powerful tool for statistical text analysis. In this tutorial we introduce a novel non-Bayesian approach, called Additive Regularization of Topic Models. ARTM is free of redundant probabilistic assumptions and provides a simple inference for many combined and multi-objective topic models.},
  date          = {2014-01-01},
  doi           = {10.1007/978-3-319-12580-0_3},
  url           = {http://dx.doi.org/10.1007/978-3-319-12580-0_3},
}

@Article{Blei2012,
  title =	"Probabilistic topic models",
  author =	"David M. Blei",
  journal =	"Commun. ACM",
  year = 	"2012",
  number =	"4",
  volume =	"55",
  bibdate =	"2012-04-20",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/journals/cacm/cacm55.html#Blei12",
  pages =	"77--84",
  URL =  	"http://doi.acm.org/10.1145/2133806.2133826",
}

@InCollection{PLSA,
  author =	"T. Hoffman",
  title =	"Probabilistic latent semantic indexing",
  booktitle =	"Proceedings of the 22nd Annual International ACM SIGIR
		 Conference on Research and Development in Information
		 Retrieval",
  publisher =	"ACM Press",
  address =	"New York",
  pages =	"50--57",
  year = 	"1999",
}

@Article{LDA,
  author =	"David M. Blei and Andrew Y. Ng and Michael I. Jordan",
  title =	"Latent Dirichlet Allocation",
  journal =	"Journal of Machine Learning Research",
  volume =	"3",
  year = 	"2003",
  pages =	"993--1022",
}

@Article{PapadimitriouEtAl00,
  author =	"Papadimitriou and Raghavan and Tamaki and Vempala",
  title =	"Latent Semantic Indexing: {A} Probabilistic Analysis",
  journal =	"JCSS: Journal of Computer and System Sciences",
  volume =	"61",
  year = 	"2000",
}

@InProceedings{ARTM1,
  title =	"Non-Bayesian Additive Regularization for Multimodal
		 Topic Modeling of Large Collections",
  author =	"Konstantin Vorontsov and Oleksandr Frei and Murat
		 Apishev and Peter Romov and Marina Suvorova and
		 Anastasia Yanina",
  bibdate =	"2015-11-06",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/cikm/tm2015.html#VorontsovFARSY15",
  booktitle =	"TM@CIKM",
  booktitle =	"Proceedings of the 2015 Workshop on Topic Models:
		 Post-Processing and Applications, {TM} 2015, Melbourne,
		 Australia, October 19, 2015",
  publisher =	"ACM",
  year = 	"2015",
  editor =	"Nikolaos Aletras and Jey Han Lau and Timothy Baldwin
		 and Mark Stevenson",
  ISBN = 	"978-1-4503-3784-7",
  pages =	"29--37",
  URL =  	"http://doi.acm.org/10.1145/2809936",
}

@InProceedings{IncHClustering,
  title =	"Incremental hierarchical clustering of text
		 documents",
  author =	"Nachiketa Sahoo and Jamie Callan and Ramayya Krishnan
		 and George T. Duncan and Rema Padman",
  bibdate =	"2006-12-14",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/cikm/cikm2006.html#SahooCKDP06",
  booktitle =	"CIKM",
  booktitle =	"Proceedings of the 2006 {ACM} {CIKM} International
		 Conference on Information and Knowledge Management,
		 Arlington, Virginia, {USA}, November 6-11, 2006",
  publisher =	"ACM",
  year = 	"2006",
  editor =	"Philip S. Yu and Vassilis J. Tsotras and Edward A. Fox
		 and Bing Liu 0001",
  ISBN = 	"1-59593-433-2",
  pages =	"357--366",
  URL =  	"http://doi.acm.org/10.1145/1183614.1183667",
}

@InProceedings{hLDA,
  author =	"D. M Blei and T. Griffiths and Michael I. Jordan and
		 J. Tenenbaum",
  year = 	"2003",
  title =	"Hierarchical Topic Models and the Nested Chinese
		 Restaurant Process",
}

@InProceedings{hPAM,
  title =	"Mixtures of hierarchical topics with Pachinko
		 allocation",
  author =	"David M. Mimno and Wei Li 0010 and Andrew McCallum",
  bibdate =	"2010-08-19",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/icml/icml2007.html#MimnoLM07",
  booktitle =	"ICML",
  booktitle =	"Machine Learning, Proceedings of the Twenty-Fourth
		 International Conference ({ICML} 2007), Corvallis,
		 Oregon, {USA}, June 20-24, 2007",
  publisher =	"ACM",
  year = 	"2007",
  volume =	"227",
  editor =	"Zoubin Ghahramani",
  ISBN = 	"978-1-59593-793-3",
  pages =	"633--640",
  series =	"ACM International Conference Proceeding Series",
  URL =  	"http://doi.acm.org/10.1145/1273496.1273576",
}


@Misc{SemiAutoGenTM,
  title =	"Framework for Semi Automatically Generating Topic
		 Maps",
  author =	"L{\'o}r{\'a}nd K{\'a}sler and Zsolt Venczel and
		 L{\'a}szl{\'o} Zsolt Varga",
  year = 	"2008",
  month =	apr # "~01",
  abstract =	". The amount of electronically stored textual
		 information is continuously increasing both on the
		 internet and in company assets, and there are no good
		 solutions to easily locate the most needed information.
		 Because search engines do not take into account the
		 meaning of the word and its context, in the end the
		 user has to select the right information from the
		 unstructured result set. If the text is annotated and
		 linked to the ontology of the annotation, then the user
		 can directly navigate along the links of the semantic
		 annotation to the desired information. In this paper we
		 present a software framework to semi automatically
		 generate a semantic representation of the knowledge of
		 the Networkshop conference series and display on a web
		 portal the generated ontology together with the
		 references to the occurrences of the instances in the
		 source text. The framework presented in this paper
		 makes advances in the following fields: we do not
		 assume that the source text has uniform and formally
		 defined structure, we address English and Hungarian
		 text as well, we incorporate machine learning
		 techniques in the process, and provide a flexible
		 content management system for the presentation of the
		 generated Topic Map on a web based portal. 1",
  bibsource =	"OAI-PMH server at citeseerx.ist.psu.edu",
  contributor =  "CiteSeerX",
  language =	"en",
  oai =  	"oai:CiteSeerXPSU:10.1.1.93.2925",
  rights =	"Metadata may be used without restrictions as long as
		 the oai identifier remains attached to it.",
  URL =  	"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.93.2925;
		 http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-205/paper7.pdf",
}


@Article{hetHTM1,
  title =	"Constructing topical hierarchies in heterogeneous
		 information networks",
  author =	"Chi Wang and Jialu Liu and Nihit Desai and Marina
		 Danilevsky and Jiawei Han",
  journal =	"Knowl. Inf. Syst",
  year = 	"2015",
  number =	"3",
  volume =	"44",
  bibdate =	"2016-02-10",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/journals/kais/kais44.html#WangLDDH15",
  pages =	"529--558",
  URL =  	"http://dx.doi.org/10.1007/s10115-014-0777-4",
}

@InProceedings{largeHTM,
  title =	"LinkedIn skills: large-scale topic extraction and
		 inference",
  author =	"Mathieu Bastian and Matthew Hayes and William Vaughan
		 and Sam Shah and Peter Skomoroch and Hyung Jin Kim and
		 Sal Uryasev and Christopher Lloyd",
  bibdate =	"2014-10-02",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/conf/recsys/recsys2014.html#BastianHVSSKUL14",
  booktitle =	"RecSys",
  booktitle =	"Eighth {ACM} Conference on Recommender Systems, RecSys
		 '14, Foster City, Silicon Valley, {CA}, {USA} - October
		 06 - 10, 2014",
  publisher =	"ACM",
  year = 	"2014",
  editor =	"Alfred Kobsa and Michelle X. Zhou and Martin Ester and
		 Yehuda Koren",
  ISBN = 	"978-1-4503-2668-1",
  pages =	"1--8",
  URL =  	"http://dl.acm.org/citation.cfm?id=2645710",
}

@Misc{ametyst,
  title =	"{AMETHYST}: {A} System for Mining and Exploring
		 Topical Hierarchies of Heterogeneous Data",
  author =	"Marina Danilevsky and Chi Wang and Fangbo Tao and Son
		 Nguyen and Gong Chen and Nihit Desai and Lidan Wang and
		 Jiawei Han",
  year = 	"2013",
  month =	dec # "~03",
  abstract =	"In this demo we present AMETHYST, a system for
		 exploring and analyzing a topical hierarchy constructed
		 from a heterogeneous information network (HIN). HINs,
		 composed of multiple types of entities and links are
		 very common in the real world. Many have a text
		 component, and thus can benefit from a high quality
		 hierarchical organization of the topics in the network
		 dataset. By organizing the topics into a hierarchy,
		 AMETHYST helps understand search results in the context
		 of an ontology, and explain entity relatedness at
		 different granularities. The automatically constructed
		 topical hierarchy reflects a domain-specific ontology,
		 interacts with multiple types of linked entities, and
		 can be tailored for both free text and OLAP queries.",
  annote =	"The Pennsylvania State University CiteSeerX Archives",
  bibsource =	"OAI-PMH server at citeseerx.ist.psu.edu",
  language =	"en",
  oai =  	"oai:CiteSeerX.psu:10.1.1.380.1298",
  rights =	"Metadata may be used without restrictions as long as
		 the oai identifier remains attached to it.",
  subject =	"Categories and Subject Descriptors I.7 [Computing
		 Methodologies; Document and Text Processing; H.2.8
		 [Database Applications; Data Mining Keywords Topic
		 Modeling; Network Analysis; Heterogeneous Network;
		 Entity Mining",
  URL =  	"http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.380.1298;
		 http://www.cs.uiuc.edu/homes/hanj/pdf/kdd13_mdanilevsky.pdf",
}

@Article{citom,
  title =	"{CITOM}: An incremental construction of multilingual
		 topic maps",
  author =	"Nebrasse Ellouze and Nadira Lammari and Elisabeth
		 M{\'e}tais",
  journal =	"Data Knowl. Eng",
  year = 	"2012",
  volume =	"74",
  bibdate =	"2012-06-04",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/journals/dke/dke74.html#EllouzeLM12",
  pages =	"46--62",
  URL =  	"http://dx.doi.org/10.1016/j.datak.2012.02.002",
}

@Book{Srivastava2009,
  title         = {Text mining: Classification, clustering, and applications},
  publisher     = {CRC Press},
  year          = {2009},
  author        = {Srivastava, Ashok N and Sahami, Mehran},
  __markedentry = {[el1318:6]},
}


@Article{extLDA1,
  title =	"The Author-Topic Model for Authors and Documents",
  author =	"Michal Rosen-Zvi and Thomas L. Griffiths and Mark
		 Steyvers and Padhraic Smyth",
  journal =	"CoRR",
  year = 	"2012",
  volume =	"abs/1207.4169",
  bibdate =	"2012-10-10",
  bibsource =	"DBLP,
		 http://dblp.uni-trier.de/db/journals/corr/corr1207.html#abs-1207-4169",
  URL =  	"http://arxiv.org/abs/1207.4169",
}

@InProceedings{extLDA3,
  author        = {Khoat Than and Tu Bao Ho},
  title         = {Fully Sparse Topic Models},
  booktitle     = {ECML/PKDD (1)},
  year          = {2012},
  editor        = {Peter A. Flach and Tijl De Bie and Nello Cristianini},
  volume        = {7523},
  series        = {Lecture Notes in Computer Science},
  pages         = {490--505},
  publisher     = {Springer},
  __markedentry = {[el1318:1]},
  bibdate       = {2012-09-10},
  bibsource     = {DBLP, http://dblp.uni-trier.de/db/conf/pkdd/pkdd2012-1.html#ThanH12},
  isbn          = {978-3-642-33459-7},
  url           = {http://dx.doi.org/10.1007/978-3-642-33460-3},
}

@Comment{jabref-meta: databaseType:bibtex;}

